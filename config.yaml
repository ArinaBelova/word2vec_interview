data:
  # Options: "file" (use file_path), "brown", "reuters", "gutenberg", "combined", "text8"
  source: "text8" #"brown"
  file_path: "data.txt"  # Only used if source is "file"
  max_sentences: null    # Limit sentences (null for all)

model:
  embedding_dim: 100
  window_size: 5
  negative_samples: 5
  subsample_threshold: 0.001  # Threshold for subsampling frequent words
  batch_size: 4096            # Larger batches for Numba parallel processing
  n_threads: 20              # Number of Numba parallel threads
  save_model_path: "word2vec_model.pkl"  # Path to save the trained model
  save_embeddings_path: "embeddings.txt"  # Path to save the embeddings in text format

training:
  epochs: 50
  learning_rate: 0.025
  log_interval: 5

wandb:
  project: "word2vec"
  entity: null
  run_name: null